{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file downloads the train, test and validation datasets used for training the CNN.\n",
    "We have used fiftyone's zoo library to download from the openImages v7.\n",
    "\n",
    "The entire Open Images V7  database size is 561 GB, It contains ~9 million images that \n",
    "around 2 million of them are annotated (Classification, Detection, Segmentation, etc.).\n",
    "The zoo library supports partial download of the entire dataset which helps a lot with \n",
    "our purpose.\n",
    "\n",
    "* All images have been rescaled so that their largest dimension is at most 1024 pixels.\n",
    "\"\"\"\n",
    "import fiftyone as fo\n",
    "import os\n",
    "import fiftyone.zoo as foz\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg # Necessary for reading an image\n",
    "import matplotlib.patches as patches # Necessary for drawing bounding boxes\n",
    "import json\n",
    "import dataHandler as handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the datasets using Fiftyone library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download two datasets, one for training and the other for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already loaded.\n"
     ]
    }
   ],
   "source": [
    "# Download the necessary data and dataset images for training. We have chosen \"open-images-v7-object-detection-DS\"\n",
    "# as the name.\n",
    "dsName = \"open-images-v7-object-detection-DS-train\"\n",
    "dsClasses = [\"Person\"]\n",
    "dsSplit = \"train\"\n",
    "dsLblTypes = [\"detections\", \"classifications\"]\n",
    "nSamples = 1000\n",
    "\n",
    "if not fo.dataset_exists(dsName):\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"open-images-v7\",\n",
    "        split = dsSplit,\n",
    "        label_types = dsLblTypes,\n",
    "        classes = dsClasses,\n",
    "        max_samples = nSamples,\n",
    "        seed = 1,\n",
    "        shuffle = True,\n",
    "        dataset_name = dsName,\n",
    "    )\n",
    "else:\n",
    "    datasetTrain = fo.load_dataset(dsName)\n",
    "    print(\"Dataset already loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already loaded. \n"
     ]
    }
   ],
   "source": [
    "# Download the necessary data and dataset images for testing. We have chosen \"open-images-v7-object-detection-DS\"\n",
    "# as the name.\n",
    "dsName = \"open-images-v7-object-detection-DS-test\"\n",
    "dsClasses = [\"Person\"]\n",
    "dsSplit = \"test\"\n",
    "dsLblTypes = [\"detections\", \"classifications\"]\n",
    "nSamples = 1000\n",
    "\n",
    "if not fo.dataset_exists(dsName):\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"open-images-v7\",\n",
    "        split = dsSplit,\n",
    "        label_types = dsLblTypes,\n",
    "        classes = dsClasses,\n",
    "        max_samples = nSamples,\n",
    "        seed = 2,\n",
    "        shuffle = True,\n",
    "        dataset_name = dsName,\n",
    "    )\n",
    "else:\n",
    "    datasetTest = fo.load_dataset(dsName)\n",
    "    print(\"Dataset already loaded. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be sure of the downloaded datasets, you can run the code below to see the downloaded datasets\n",
    "# List the current datasets\n",
    "fo.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the datasets to two directories. Each one containing two sub-directories, namely, images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the downloaded datasets to the desired locations.\n",
    "# Check if the path exists\n",
    "if not os.path.isdir(\"./data/images/train/\"):\n",
    "    os.makedirs(\"./data/images/train/\", exist_ok = True)\n",
    "if not os.path.isdir(\"./data/labels/train/\"):\n",
    "    os.makedirs(\"./data/labels/train/\", exist_ok = True)\n",
    "\n",
    "# Test data\n",
    "datasetTrain.export(\n",
    "    data_path = \"./data/images/train\",\n",
    "    labels_path = \"./data/labels/train/labels.json\",\n",
    "    dataset_type = fo.types.FiftyOneImageDetectionDataset,\n",
    "    classes = dsClasses,\n",
    "    include_confidence = False\n",
    ")\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.isdir(\"./data/images/test\"):\n",
    "    os.makedirs(\"./data/images/test\", exist_ok = True)\n",
    "if not os.path.isdir(\"./data/labels/test/\"):\n",
    "    os.makedirs(\"./data/labels/test/\", exist_ok = True)\n",
    "# Test data\n",
    "datasetTest.export(\n",
    "    data_path = \"./data/images/test\",\n",
    "    labels_path = \"./data/labels/test/labels.json\",\n",
    "    dataset_type = fo.types.FiftyOneImageDetectionDataset,\n",
    "    classes = dsClasses,\n",
    "    include_confidence = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize the json file and convert it to text files to make it compatible with YOLO-v1\n",
    "# Training dataset\n",
    "file = open(\"./data/labels/train/labels.json\")\n",
    "js = json.load(file)\n",
    "for item in js[\"labels\"]:\n",
    "    txt = \"\"\n",
    "    with open(f\"./data/labels/train/{item}.txt\", 'w') as txtFile:\n",
    "        for subItem in js[\"labels\"][item]: \n",
    "            width = subItem[\"bounding_box\"][2]\n",
    "            height = subItem[\"bounding_box\"][3]\n",
    "            centerX = subItem[\"bounding_box\"][0] + width/2\n",
    "            centerY = subItem[\"bounding_box\"][1] + height/2\n",
    "            label = subItem[\"label\"]\n",
    "            txt += f\"{label} {centerX} {centerY} {width} {height}\\n\"\n",
    "        txtFile.write(txt)\n",
    "        txtFile.close()\n",
    "    \n",
    "\n",
    "file = open(\"./data/labels/test/labels.json\")\n",
    "js = json.load(file)\n",
    "for item in js[\"labels\"]:\n",
    "    txt = \"\"\n",
    "    with open(f\"./data/labels/test/{item}.txt\", 'w') as txtFile:\n",
    "        for subItem in js[\"labels\"][item]: \n",
    "            width = subItem[\"bounding_box\"][2]\n",
    "            height = subItem[\"bounding_box\"][3]\n",
    "            centerX = subItem[\"bounding_box\"][0] + width/2\n",
    "            centerY = subItem[\"bounding_box\"][1] + height/2\n",
    "            label = subItem[\"label\"]\n",
    "            txt += f\"{label} {centerX} {centerY} {width} {height}\\n\"\n",
    "        txtFile.write(txt)\n",
    "        txtFile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the downloaded datasets. Might not work on the server-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the samples\n",
    "aa = fo.load_dataset(\"open-images-v7-object-detection-DS-test\")\n",
    "session = fo.launch_app(aa.view())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove grayscale images \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "files = os.listdir(\"./data/images/test\")\n",
    "\n",
    "for file in files:\n",
    "    img = np.array(Image.open(\"./data/images/test/\"+file))\n",
    "    if img.ndim == 2:\n",
    "        print(f\"Removed image {file} and its respective label.\")\n",
    "        os.remove(\"./data/images/test/\"+file)\n",
    "        os.remove(\"./data/labels/test/\"+file.replace(\".jpg\",\".txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove images with four channels\n",
    "# Alternatively, you can replace the image as well.\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "files = os.listdir(\"./data/images/test\")\n",
    "\n",
    "for file in files:\n",
    "    img = np.array(Image.open(\"./data/images/test/\"+file))\n",
    "    if img.shape[2] == 4:\n",
    "        print(f\"Removed image {file} and its respective label.\")\n",
    "        os.remove(\"./data/images/test/\"+file)\n",
    "        os.remove(\"./data/labels/test/\"+file.replace(\".jpg\",\".txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
